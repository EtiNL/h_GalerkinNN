{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54455791-e004-4866-868a-c4da186da91a",
   "metadata": {},
   "source": [
    "# Equidistributed initial conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f5b27a-883f-4f77-913d-4a5575c7c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "\n",
    "@torch.no_grad()\n",
    "def sobol_sphere(N: int, K: int, device=\"cuda\", dtype=torch.float32) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Deterministic low-discrepancy points on S^{K-1}.\n",
    "    Returns A: (N,K) with ||A[i]||2=1.\n",
    "    \"\"\"\n",
    "    eng = torch.quasirandom.SobolEngine(dimension=K, scramble=False)\n",
    "    U = eng.draw(N).to(device=device, dtype=dtype)  # (N,K) in [0,1)\n",
    "    eps = torch.finfo(dtype).eps\n",
    "    U = U.clamp(eps, 1 - eps)\n",
    "    G = math.sqrt(2.0) * torch.erfinv(2 * U - 1)    # inverse Normal CDF\n",
    "    A = G / G.norm(dim=1, keepdim=True)\n",
    "    return A\n",
    "    \n",
    "@torch.no_grad()\n",
    "def gram_correct(A: torch.Tensor, Phi: torch.Tensor, w: torch.Tensor, jitter=1e-10) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    A: (N,K) unit sphere in R^K\n",
    "    Phi: (K,nx)\n",
    "    w: (nx,)\n",
    "    returns C: (N,K) s.t. C^T M C = I approximately (M = Phi diag(w) Phi^T)\n",
    "    \"\"\"\n",
    "    # M = (Phi * w) @ Phi^T\n",
    "    M = (Phi * w.unsqueeze(0)) @ Phi.t()\n",
    "    M = 0.5 * (M + M.t()) + jitter * torch.eye(M.shape[0], device=M.device, dtype=M.dtype)\n",
    "    L = torch.linalg.cholesky(M)\n",
    "    # C = L^{-T} A  (solve L^T C^T = A^T)\n",
    "    C_T = torch.linalg.solve_triangular(L.t(), A.t(), upper=True)\n",
    "    return C_T.t()\n",
    "\n",
    "@torch.no_grad()\n",
    "def interp_time_rows(t_grid: torch.Tensor, U_grid: torch.Tensor, t_query: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    t_grid: (ntg,)\n",
    "    U_grid: (ntg,nx)\n",
    "    t_query: (nT,)\n",
    "    returns Uq: (nT,nx) linear interpolation in time.\n",
    "    Assumes t_query in [t_grid[0], t_grid[-1]] (clamps softly).\n",
    "    \"\"\"\n",
    "    t0 = t_grid[0]\n",
    "    t1 = t_grid[-1]\n",
    "    tq = t_query.clamp(t0, t1)\n",
    "\n",
    "    idx = torch.searchsorted(t_grid, tq, right=False)\n",
    "    idx = idx.clamp(1, t_grid.numel() - 1)\n",
    "\n",
    "    t_lo = t_grid[idx - 1]\n",
    "    t_hi = t_grid[idx]\n",
    "    w = (tq - t_lo) / (t_hi - t_lo)\n",
    "\n",
    "    U_lo = U_grid[idx - 1]\n",
    "    U_hi = U_grid[idx]\n",
    "    return (1 - w).unsqueeze(1) * U_lo + w.unsqueeze(1) * U_hi\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from dataclasses import dataclass\n",
    "from typing import Callable, List, Optional\n",
    "\n",
    "# uses your existing trapz_weights_1d + NeuralGalerkinDatasetConfig + NeuralGalerkinDataset\n",
    "# from neural_galerkin_ode.py :contentReference[oaicite:4]{index=4} :contentReference[oaicite:5]{index=5}\n",
    "\n",
    "@torch.no_grad()\n",
    "def create_NeuralGalerkin_dataset_fast_gpu(\n",
    "    solution_functions: List,                 # ideally BurgersSolution objects\n",
    "    x_grid: np.ndarray,\n",
    "    t_min: float,\n",
    "    t_max: float,\n",
    "    basis_eval: Callable[[np.ndarray], np.ndarray],  # returns (K,nx)\n",
    "    n_time_samples: int = 200,\n",
    "    t_sampling: str = \"grid\",\n",
    "    seed: Optional[int] = 0,\n",
    "    weights: Optional[np.ndarray] = None,\n",
    "    device: str = \"cuda\",\n",
    "    dtype: torch.dtype = torch.float32,\n",
    "    normalize_t: bool = False,\n",
    "    normalize_c: bool = False,\n",
    "    return_k_coords: bool = False,\n",
    "    pde_name: str = \"unknown\",\n",
    "    batch_size: int = 8,\n",
    "):\n",
    "    from .neural_galerkin_ode import trapz_weights_1d, NeuralGalerkinDatasetConfig, NeuralGalerkinDataset\n",
    "\n",
    "    x_grid = np.asarray(x_grid, dtype=float)\n",
    "    M = len(solution_functions)\n",
    "    if weights is None:\n",
    "        weights = trapz_weights_1d(x_grid)  # :contentReference[oaicite:6]{index=6}\n",
    "    w = torch.tensor(weights, device=device, dtype=dtype)  # (nx,)\n",
    "\n",
    "    # time samples\n",
    "    if t_sampling == \"grid\":\n",
    "        t_1d = torch.linspace(t_min, t_max, n_time_samples, device=device, dtype=dtype)\n",
    "        T_all = t_1d.unsqueeze(0).repeat(M, 1)  # (M,nT)\n",
    "    elif t_sampling == \"random\":\n",
    "        g = torch.Generator(device=\"cpu\")\n",
    "        if seed is not None:\n",
    "            g.manual_seed(int(seed))\n",
    "        tr = torch.rand((M, n_time_samples), generator=g).to(device=device, dtype=dtype)\n",
    "        T_all = (t_min + (t_max - t_min) * tr).sort(dim=1).values\n",
    "    else:\n",
    "        raise ValueError(\"t_sampling must be 'grid' or 'random'\")\n",
    "\n",
    "    # basis + projection matrix on GPU\n",
    "    Phi_np = np.asarray(basis_eval(x_grid), dtype=float)  # (K,nx) :contentReference[oaicite:7]{index=7}\n",
    "    Phi = torch.tensor(Phi_np, device=device, dtype=dtype)\n",
    "    P = (w.unsqueeze(0) * Phi).t().contiguous()          # (nx,K)\n",
    "\n",
    "    K = Phi.shape[0]\n",
    "    C_all = torch.empty((M, n_time_samples, K), device=device, dtype=dtype)\n",
    "\n",
    "    # batch over trajectories\n",
    "    for i0 in range(0, M, batch_size):\n",
    "        i1 = min(M, i0 + batch_size)\n",
    "        for m in range(i0, i1):\n",
    "            sol = solution_functions[m]\n",
    "\n",
    "            # Fast path for BurgersSolution: use precomputed grid (CPU->GPU once)\n",
    "            if hasattr(sol, \"U\") and hasattr(sol, \"t_vals\") and hasattr(sol, \"z_vals\"):\n",
    "                # assumes x_grid matches sol.z_vals (your code already enforces this) :contentReference[oaicite:8]{index=8}\n",
    "                U_grid = torch.tensor(sol.U, device=device, dtype=dtype)        # (ntg,nx)\n",
    "                t_grid = torch.tensor(sol.t_vals, device=device, dtype=dtype)   # (ntg,)\n",
    "                Uq = interp_time_rows(t_grid, U_grid, T_all[m])                # (nT,nx)\n",
    "            else:\n",
    "                # Fallback: calls the function (CPU), then moves to GPU\n",
    "                t_m = T_all[m].detach().cpu().numpy()\n",
    "                Tm = np.repeat(t_m[:, None], x_grid.size, axis=1)\n",
    "                Xm = np.repeat(x_grid[None, :], t_m.size, axis=0)\n",
    "                U_cpu = np.asarray(sol(Tm, Xm), dtype=float)\n",
    "                Uq = torch.tensor(U_cpu, device=device, dtype=dtype)\n",
    "\n",
    "            C_all[m] = Uq @ P  # (nT,K)\n",
    "\n",
    "    # normalization stats (keep as numpy scalars/arrays for compatibility with your Dataset) :contentReference[oaicite:9]{index=9}\n",
    "    t_mean = float(T_all.mean().item())\n",
    "    t_std  = float(T_all.std(unbiased=False).item() + 1e-8)\n",
    "    c_mean = C_all.reshape(-1, K).mean(dim=0, keepdim=True).detach().cpu().numpy()\n",
    "    c_std  = (C_all.reshape(-1, K).std(dim=0, unbiased=False, keepdim=True) + 1e-8).detach().cpu().numpy()\n",
    "\n",
    "    T_store = T_all\n",
    "    C_store = C_all\n",
    "    if normalize_t:\n",
    "        T_store = (T_store - t_mean) / t_std\n",
    "    if normalize_c:\n",
    "        C_store = (C_store - torch.tensor(c_mean, device=device, dtype=dtype)) / torch.tensor(c_std, device=device, dtype=dtype)\n",
    "\n",
    "    cfg = NeuralGalerkinDatasetConfig(\n",
    "        n_time_samples=n_time_samples,\n",
    "        t_sampling=t_sampling,\n",
    "        seed=seed,\n",
    "        normalize_t=normalize_t,\n",
    "        normalize_c=normalize_c,\n",
    "        return_k_coords=return_k_coords,\n",
    "        pde_name=pde_name,\n",
    "    )\n",
    "\n",
    "    # Construct dataset in the simplest compatible way: pass *physical* arrays to keep save/load semantics.\n",
    "    # NeuralGalerkinDataset will move to `device` internally. :contentReference[oaicite:10]{index=10}\n",
    "    ds = NeuralGalerkinDataset(\n",
    "        cfg,\n",
    "        t=T_all.detach().cpu().numpy(),\n",
    "        c=C_all.detach().cpu().numpy(),\n",
    "        device=device,\n",
    "        dtype=dtype,\n",
    "        x_grid=x_grid,\n",
    "        basis_matrix=Phi_np,\n",
    "    )\n",
    "    return ds\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
